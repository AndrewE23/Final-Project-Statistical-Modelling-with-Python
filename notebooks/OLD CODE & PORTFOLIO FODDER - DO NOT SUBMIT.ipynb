{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1475a955",
   "metadata": {},
   "source": [
    "## NOTE: This is old code, kept for documentation purposes (e.g. for future portfolio construction). THIS IS NOT INTENDED TO BE PART OF THE ASSIGNMENT SUBMISSION."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25338743",
   "metadata": {},
   "source": [
    "I was doing my process a certain way before it clicked that I should approach my goal differently. That said, I am genuinely happy that I worked out some of the code that I did, and want to keep it handy (it can also be useful to highlight my thought processes and maybe scour for other insights down the road)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f08096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, I want to check for and drop duplicates.\n",
    "duplicate_stations_df = stations_df[stations_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_stations_df.shape)\n",
    "\n",
    "duplicate_fsq_df = fsq_df[fsq_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_fsq_df.shape)\n",
    "\n",
    "duplicate_yelp_df = yelp_df[yelp_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_yelp_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67958646",
   "metadata": {},
   "source": [
    "Note: Lots of duplicates were expected in the FourSquare (7646) and Yelp (5291) DataFrames because the query was set to repeat for every bike station coordinate pair, meaning there would be a lot of overlap within overlapping radii.\n",
    "\n",
    "Additionally, some results in the FourSquare DataFrame may be duplicated except for a custom column I added, 'fsq_am_cat' (FourSquare Amalgamated Category), so I want to be sure I delete extra duplicates as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and reset index for each DataFrame.\n",
    "# There may be overlap in the FourSquare DataFrame, so I want to ignore the custom category column:\n",
    "fsq_df = fsq_df.drop_duplicates(subset=fsq_df.columns.difference(['fsq_am_cat']))\n",
    "fsq_df = fsq_df.reset_index(drop=True)\n",
    "yelp_df = yelp_df.drop_duplicates()\n",
    "yelp_df = yelp_df.reset_index(drop=True)\n",
    "\n",
    "print(\"Number of unique FourSquare instances = \", fsq_df.shape)\n",
    "print(\"Number of unique Yelp instances = \", yelp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebad3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NULL/NaN values:\n",
    "print(fsq_df.isnull().sum())\n",
    "print('-' * 24)\n",
    "print(yelp_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e992461",
   "metadata": {},
   "source": [
    "Not a lot of null values for the datasets, which I am happy with.\n",
    "\n",
    "However, the postal code nulls that are present in the FSQ DataFrame are likely going to be places where there is no sense in having a postal code, such as parks. I need to therefore join on coordinates, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9368803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Country and Province indiciators; while FSQ's sometimes uses either \"ON\" or \"Ontario\",\n",
    "# they are all in Ontario Canada.\n",
    "fsq_df.drop(['location.country',\n",
    "              'location.region'\n",
    "             ], axis=1, inplace=True)\n",
    "\n",
    "yelp_df.drop(['location.country',\n",
    "              'location.state'\n",
    "             ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdc651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, rename some columns for consistency's sake:\n",
    "fsq_df = fsq_df.rename(columns={\n",
    "    'geocodes.main.latitude':'latitude', \n",
    "    'geocodes.main.longitude':'longitude',\n",
    "    'location.postcode':'postcode',\n",
    "    'location.locality':'locality',\n",
    "    'location.address':'address',\n",
    "    'id':'fsq_id'\n",
    "    })\n",
    "yelp_df = yelp_df.rename(columns={\n",
    "    'coordinates.latitude':'latitude', \n",
    "    'coordinates.longitude':'longitude',\n",
    "    'location.address1':'address',\n",
    "    'location.city':'locality',\n",
    "    'location.zip_code':'postcode',\n",
    "    'id':'yelp_id'\n",
    "    })\n",
    "\n",
    "# Also add prefixes to IDs, so that where they came from can be identified.\n",
    "fsq_df['fsq_id'] = 'fq-' + fsq_df['fsq_id'].astype(str)\n",
    "yelp_df['yelp_id'] = 'yp-' + yelp_df['yelp_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c975e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate Coordinates in clones DataFrames, to avoid issue where coordinates are not identical\n",
    "# between tilesets (to three decimal points):\n",
    "fsq_df2 = fsq_df.sort_values(['latitude','longitude']).copy()\n",
    "# fsq_df2['latitude'] = ((fsq_df2['latitude']*1000).astype(int).astype(float))/1000\n",
    "# fsq_df2['longitude'] = ((fsq_df2['longitude']*1000).astype(int).astype(float))/1000\n",
    "yelp_df2 = yelp_df.sort_values(['latitude','longitude']).copy()\n",
    "# yelp_df2['latitude'] = ((yelp_df2['latitude']*1000).astype(int).astype(float))/1000\n",
    "# yelp_df2['longitude'] = ((yelp_df2['longitude']*1000).astype(int).astype(float))/1000\n",
    "\n",
    "joint_query_df = pd.merge_asof(\n",
    "    fsq_df2,\n",
    "    yelp_df2,\n",
    "    by=['latitude', 'longitude'],\n",
    "    \n",
    "    direction=\"nearest\")\n",
    "\n",
    "\n",
    "# Join DataFrames:\n",
    "# joint_query_df = fsq_df2.merge(yelp_df2, how='inner', on=['latitude','longitude'])\n",
    "joint_duplicates_df = joint_query_df[joint_query_df.duplicated()]\n",
    "print(\"Joined entry shape: \", joint_query_df.shape)\n",
    "print(\"Number of rows x columns: \", joint_duplicates_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cca292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, I want to add the closest bike station to every entry.\n",
    "\n",
    "stations_df2 = stations_df.sort_values(['latitude','longitude']).copy()\n",
    "joint_query_df2 = joint_query_df.sort_values(['latitude','longitude']).copy()\n",
    "\n",
    "# pd.merge_asof(\n",
    "    \n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
